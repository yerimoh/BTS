{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Chapter 03 - 롤 좀 하니_ 이것만 하면 무조건 이긴다! - 데이터로 알아보는 리그 오브 레전드의 승리 공식(문제).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqqLNJZjfi8U"
      },
      "source": [
        "# 주제 : 롤 좀 하니? '이것'만 하면 무조건 이긴다!<br> - 데이터로 알아보는 리그 오브 레전드의 승리 공식\n",
        "----------\n",
        "\n",
        "## 실습 가이드\n",
        "    1. 데이터를 다운로드하여 Colab에 불러옵니다.\n",
        "    2. 필요한 라이브러리는 모두 코드로 작성되어 있습니다.\n",
        "    3. 코드는 위에서부터 아래로 순서대로 실행합니다.\n",
        "    \n",
        "    \n",
        "## 데이터 소개\n",
        "    - 이번 주제는 League of Legends Diamond Ranked Games (10 min) 데이터셋을 사용합니다.\n",
        "    \n",
        "    - 다음 1개의 csv 파일을 사용합니다.\n",
        "    high_diamond_ranked_10min.csv\n",
        "    \n",
        "    - 각 파일의 컬럼은 아래와 같습니다.\n",
        "    gameId: 게임 판의 고유 ID\n",
        "    blueWins: 블루팀의 승리 여부 (0: 패배, 1: 승리)\n",
        "    xxxWardsPlaced: xxx팀에서 설치한 와드의 수 \n",
        "    xxxWardsDestroyed: xxx팀에서 파괴한 와드의 수\n",
        "    xxxFirstBlood: xxx팀의 첫번째 킬 달성 여부\n",
        "    xxxKills: xxx팀의 킬 수\n",
        "    xxxDeaths: xxx팀의 죽음 수\n",
        "    xxxAssists: xxx팀의 어시스트 수\n",
        "    xxxEliteMonsters: xxx팀이 죽인 엘리트 몬스터 수\n",
        "    xxxDragons: xxx팀이 죽인 용의 수\n",
        "    xxxHeralds: xxx팀이 죽인 전령의 수\n",
        "    xxxTowersDestroyed: xxx팀이 파괴한 탑의 수\n",
        "    xxxTotalGold: xxx팀의 전체 획득 골드\n",
        "    xxxAvgLevel: xxx팀의 평균 레벨\n",
        "    xxxTotalExperience: xxx팀의 총 경험치 획득량\n",
        "    xxxTotalMinionsKilled: xxx팀의 총 미니언 킬 수\n",
        "    xxxTotalJungleMinionsKilled: xxx팀의 총 정글 미니언 킬 수\n",
        "    xxxGoldDiff: xxx팀과 다른 팀 간의 골드 획득량 차이\n",
        "    xxxExperienceDiff: xxx팀과 다른 팀과의 경험치 획득량 차이\n",
        "    xxxCSPerMin: xxx팀의 분당 CS 스코어\n",
        "    xxxGoldPerMin: xxx팀의 분당 골드 획득량\n",
        "      \n",
        "    \n",
        "    \n",
        "- 데이터 출처: https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min\n",
        "\n",
        "## 최종 목표\n",
        "    - 일상에서 볼 수 있는 데이터의 활용\n",
        "    - 데이터 시각화를 통한 인사이트 습득 방법의 이해\n",
        "    - Scikit-learn 기반의 모델 학습 방법 습득\n",
        "    - 학습된 모델로부터 인사이트 습득 방법 이해\n",
        "\n",
        "- 출제자 : 신제용 강사\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODJVmYvIP3x-"
      },
      "source": [
        "## Step 0. 리그 오브 레전드 데이터셋"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0iKTnLNsraM"
      },
      "source": [
        "### E-스포츠와 리그 오브 레전드\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxZwPnfms0-9"
      },
      "source": [
        "### 리그 오브 레전드 데이터셋에 관하여\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRssoNrgP7So"
      },
      "source": [
        "## Step 1. 데이터셋 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g49RuFGrBvt7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paInbv8Ys-Qy"
      },
      "source": [
        "### 문제 1. Colab Notebook에 Kaggle API 세팅하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRXGYV60B7FX"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMKFOC0OBtHO"
      },
      "source": [
        "# os.environ을 이용하여 Kaggle API Username, Key 세팅하기\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = 'bora3328'\n",
        "os.environ['KAGGLE_KEY'] = 'eeee968de5624796ad5d4fdf85257bfb'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvbeoB_WtBi-"
      },
      "source": [
        "### 문제 2. 데이터 다운로드 및 압축 해제하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSblp2NsCGbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278aecac-0d61-4048-9416-53b7c43522d7"
      },
      "source": [
        "# Linux 명령어로 Kaggle API를 이용하여 데이터셋 다운로드하기 (!kaggle ~)\n",
        "# Linux 명령어로 압축 해제하기\n",
        "\n",
        "! kaggle datasets download -d bobbyscience/league-of-legends-diamond-ranked-games-10-min\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "league-of-legends-diamond-ranked-games-10-min.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ34SovLtFI8"
      },
      "source": [
        "### 문제 3. Pandas 라이브러리로 csv파일 읽어들이기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnJv-4YwCMSx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "394123de-5d49-4e4c-dd16-64ef44a5499c"
      },
      "source": [
        "# pd.read_csv()로 csv파일 읽어들이기\n",
        "df = pd.read_csv('C:/Users/bora3/Downloads/archive (1)/high_diamond_ranked_10min.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-71b97577f666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pd.read_csv()로 csv파일 읽어들이기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Users/bora3/Downloads/archive (1)/high_diamond_ranked_10min.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/bora3/Downloads/archive (1)/high_diamond_ranked_10min.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L3BNVM7tHN5"
      },
      "source": [
        "## Step 2. EDA 및 데이터 기초 통계 분석\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyFm33tNtVn7"
      },
      "source": [
        "### 문제 4. 데이터프레임의 각 컬럼 분석하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcR9BX23DIFW"
      },
      "source": [
        "# DataFrame에서 제공하는 메소드를 이용하여 컬럼 분석하기 (head(), info(), describe())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGHvPwkNtXgj"
      },
      "source": [
        "### 문제 5. 각 컬럼의 Correlation 히트맵으로 시각화하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZXSBFPyDh6R"
      },
      "source": [
        "# DataFrame의 corr() 메소드와 Seaborn의 heatmap() 메소드를 이용하여 Pearson's correlation 시각화하기\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KywGh9sjtYl9"
      },
      "source": [
        "### 문제 6. 각 컬럼과 승리 여부의 관계 시각화하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqXkwW8JDxhH"
      },
      "source": [
        "# Seaborn의 countplot() 및 histplot()을 사용하여 각 컬럼과 승/패의 관계를 시각화\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD18QuastZy8"
      },
      "source": [
        "## Step 3. 모델 학습을 위한 데이터 전처리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dev2yLeMta85"
      },
      "source": [
        "### 문제 7. StandardScaler를 이용해 수치형 데이터 표준화하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k_SDCh5xMgD"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3EO22NCE3wG"
      },
      "source": [
        "# StandardScaler를 이용해 수치형 데이터를 표준화하기\n",
        "# Hint) Multicollinearity를 피하기 위해 불필요한 컬럼은 drop한다.\n",
        "\n",
        "X_num = \n",
        "X_cat =\n",
        "X = \n",
        "y = df['blueWins']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x93Tb6lptcA2"
      },
      "source": [
        "### 문제 8. 학습데이터와 테스트데이터 분리하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9kMQI8SEche"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F07QjOFwFNEw"
      },
      "source": [
        "# train_test_split() 함수로 학습 데이터와 테스트 데이터 분리하기\n",
        "X_train, X_test, y_train, y_test = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTqb-HqPtc4I"
      },
      "source": [
        "## Step 4. Classification 모델 학습하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckexl202tmZI"
      },
      "source": [
        "### 문제 9. Logistic Regression 모델 생성/학습하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wt_0AdNFfbN"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lM57a_8Fdbh"
      },
      "source": [
        "# LogisticRegression 모델 생성/학습\n",
        "model_lr = \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APOI7Hc9tnvr"
      },
      "source": [
        "### 문제 10. 모델 학습 결과 평가하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lIoyMjFFrif"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dD9JnN-FnpC"
      },
      "source": [
        "# Predict를 수행하고 classification_report() 결과 출력하기\n",
        "pred = \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTRTOLTNto3h"
      },
      "source": [
        "### 문제 11. XGBoost 모델 생성/학습하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow28ZRL4F7D5"
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSSNqFUrGM6R"
      },
      "source": [
        "# XGBClassifier 모델 생성/학습\n",
        "model_xgb = \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAisZoSEtp35"
      },
      "source": [
        "### 문제 12. 모델 학습 결과 평가하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLnyYNJwGRgd"
      },
      "source": [
        "# Predict를 수행하고 classification_report() 결과 출력하기\n",
        "pred = \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7icVVlSwtr53"
      },
      "source": [
        "## Step5 모델 학습 결과 심화 분석하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmaEIOOItvJa"
      },
      "source": [
        "### 문제 13. Logistic Regression 모델 계수로 상관성 파악하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUIXk9RNGnRa"
      },
      "source": [
        "# Logistic Regression 모델의 coef_ 속성을 plot하기\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yIbQKjktuwg"
      },
      "source": [
        "### 문제 14. XGBoost 모델로 특징의 중요도 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bY4SZZ4HBdN"
      },
      "source": [
        "# XGBoost 모델의 feature_importances_ 속성을 plot하기\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}